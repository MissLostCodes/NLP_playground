{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U9uk5d24_n94",
        "outputId": "27b988b3-b4c3-4529-9c9e-4f57f51766b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn gensim nltk pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NLP Techniques Demo:\n",
        "- Bag of Words\n",
        "- TF-IDF\n",
        "- Naive Bayes classifier\n",
        "- Word2Vec using Gensim\n",
        "\n",
        "Collaboration-friendly structure:\n",
        "- Functions separated by task\n",
        "- Clear comments\n",
        "- Easy dataset swap\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Sample dataset (replace with real dataset anytime)\n",
        "# -------------------------------------------------\n",
        "def load_sample_data():\n",
        "    data = {\n",
        "        \"text\": [\n",
        "            \"I love machine learning\",\n",
        "            \"AI is amazing\",\n",
        "            \"I hate bugs in code\",\n",
        "            \"Debugging is frustrating\",\n",
        "            \"Machine learning is fun\",\n",
        "            \"AI will shape future\"\n",
        "        ],\n",
        "        \"label\": [\"pos\", \"pos\", \"neg\", \"neg\", \"pos\", \"pos\"]\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# BAG OF WORDS\n",
        "# -------------------------------------------------\n",
        "def bag_of_words(corpus):\n",
        "    print(\"\\n===== BAG OF WORDS =====\")\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    print(\"Vocabulary:\")\n",
        "    print(vectorizer.get_feature_names_out())\n",
        "\n",
        "    print(\"\\nBoW Matrix:\")\n",
        "    print(X.toarray())\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# TF-IDF\n",
        "# -------------------------------------------------\n",
        "def tfidf_features(corpus):\n",
        "    print(\"\\n===== TF-IDF =====\")\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    print(\"Vocabulary:\")\n",
        "    print(vectorizer.get_feature_names_out())\n",
        "\n",
        "    print(\"\\nTF-IDF Matrix:\")\n",
        "    print(X.toarray())\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# NAIVE BAYES CLASSIFIER\n",
        "# -------------------------------------------------\n",
        "def naive_bayes_classifier(texts, labels):\n",
        "    print(\"\\n===== NAIVE BAYES TEXT CLASSIFIER =====\")\n",
        "\n",
        "    # Pipeline combines TF-IDF + Naive Bayes\n",
        "    model = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer()),\n",
        "        (\"nb\", MultinomialNB())\n",
        "    ])\n",
        "\n",
        "    model.fit(texts, labels)\n",
        "\n",
        "    test_sentences = [\n",
        "        \"AI is powerful\",\n",
        "        \"I hate errors\"\n",
        "    ]\n",
        "\n",
        "    predictions = model.predict(test_sentences)\n",
        "\n",
        "    for sent, pred in zip(test_sentences, predictions):\n",
        "        print(f\"{sent} -> {pred}\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# WORD2VEC USING GENSIM\n",
        "# -------------------------------------------------\n",
        "def train_word2vec(corpus):\n",
        "    print(\"\\n===== WORD2VEC (GENSIM) =====\")\n",
        "\n",
        "    tokenized = [nltk.word_tokenize(text.lower()) for text in corpus]\n",
        "\n",
        "    model = Word2Vec(\n",
        "        sentences=tokenized,\n",
        "        vector_size=50,\n",
        "        window=3,\n",
        "        min_count=1,\n",
        "        workers=4\n",
        "    )\n",
        "\n",
        "    print(\"Vector for 'ai':\")\n",
        "    print(model.wv[\"ai\"])\n",
        "\n",
        "    print(\"\\nMost similar words to 'machine':\")\n",
        "    print(model.wv.most_similar(\"machine\"))\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# MAIN EXECUTION\n",
        "# -------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    df = load_sample_data()\n",
        "\n",
        "    corpus = df[\"text\"]\n",
        "    labels = df[\"label\"]\n",
        "\n",
        "    bag_of_words(corpus)\n",
        "    tfidf_features(corpus)\n",
        "    naive_bayes_classifier(corpus, labels)\n",
        "    train_word2vec(corpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWmJK9g1_qSY",
        "outputId": "e98e332c-00ea-4154-c7dd-c3610e58d856"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== BAG OF WORDS =====\n",
            "Vocabulary:\n",
            "['ai' 'amazing' 'bugs' 'code' 'debugging' 'frustrating' 'fun' 'future'\n",
            " 'hate' 'in' 'is' 'learning' 'love' 'machine' 'shape' 'will']\n",
            "\n",
            "BoW Matrix:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
            " [1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1]]\n",
            "\n",
            "===== TF-IDF =====\n",
            "Vocabulary:\n",
            "['ai' 'amazing' 'bugs' 'code' 'debugging' 'frustrating' 'fun' 'future'\n",
            " 'hate' 'in' 'is' 'learning' 'love' 'machine' 'shape' 'will']\n",
            "\n",
            "TF-IDF Matrix:\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.5355058\n",
            "  0.65304446 0.5355058  0.         0.        ]\n",
            " [0.55902156 0.68172171 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.47196441 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.5        0.5        0.         0.\n",
            "  0.         0.         0.5        0.5        0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.63509072 0.63509072\n",
            "  0.         0.         0.         0.         0.4396812  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.59505434 0.         0.         0.         0.41196351 0.48795307\n",
            "  0.         0.48795307 0.         0.        ]\n",
            " [0.42790272 0.         0.         0.         0.         0.\n",
            "  0.         0.52182349 0.         0.         0.         0.\n",
            "  0.         0.         0.52182349 0.52182349]]\n",
            "\n",
            "===== NAIVE BAYES TEXT CLASSIFIER =====\n",
            "AI is powerful -> pos\n",
            "I hate errors -> pos\n",
            "\n",
            "===== WORD2VEC (GENSIM) =====\n",
            "Vector for 'ai':\n",
            "[-0.01632739  0.00900212 -0.0082787   0.00164675  0.01700753 -0.00892987\n",
            "  0.00903817 -0.01357233 -0.00709448  0.01879954 -0.00315115  0.00064603\n",
            " -0.00828203 -0.01537338 -0.00301129  0.00493895 -0.00177075  0.0110675\n",
            " -0.00549243  0.00452751  0.01091556  0.01669441 -0.00290318 -0.01841635\n",
            "  0.00873827  0.00114404  0.01489446 -0.00162494 -0.00527714 -0.01751204\n",
            " -0.00171338  0.00565253  0.01080052  0.01410975 -0.01140741  0.00372575\n",
            "  0.01218874 -0.00960402 -0.00622213  0.01360566  0.00326445  0.00038265\n",
            "  0.00695468  0.0004343   0.01924732  0.01012635 -0.01783788 -0.01408821\n",
            "  0.00180028  0.01278821]\n",
            "\n",
            "Most similar words to 'machine':\n",
            "[('in', 0.1901303380727768), ('will', 0.04489828646183014), ('fun', -0.010188843123614788), ('is', -0.014479419216513634), ('debugging', -0.02330494299530983), ('shape', -0.04409411922097206), ('code', -0.0948818102478981), ('frustrating', -0.12283718585968018), ('hate', -0.15020276606082916), ('learning', -0.15516114234924316)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQz4IkysACG5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}